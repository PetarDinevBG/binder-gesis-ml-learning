{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from gensim import corpora\n",
    "from gensim import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [\"In the train from Connecticut to New York\", \n",
    "             \"He is a spokesman for New York City's Health Department\",\n",
    "             \"New York has been one of the states hit hardest by Coronavirus\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents_bigrams = [[\"_\".join(tup) for tup in nltk.ngrams(doc.split(),2)] for doc in documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents) == len(documents_bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# maybe we want both unigrams and bigrams in the feature set?\n",
    "documents_uniandbigrams = []\n",
    "for a,b in zip([doc.split() for doc in documents],documents_bigrams):\n",
    "    documents_uniandbigrams.append(a + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['In',\n",
       "  'the',\n",
       "  'train',\n",
       "  'from',\n",
       "  'Connecticut',\n",
       "  'to',\n",
       "  'New',\n",
       "  'York',\n",
       "  'In_the',\n",
       "  'the_train',\n",
       "  'train_from',\n",
       "  'from_Connecticut',\n",
       "  'Connecticut_to',\n",
       "  'to_New',\n",
       "  'New_York'],\n",
       " ['He',\n",
       "  'is',\n",
       "  'a',\n",
       "  'spokesman',\n",
       "  'for',\n",
       "  'New',\n",
       "  'York',\n",
       "  \"City's\",\n",
       "  'Health',\n",
       "  'Department',\n",
       "  'He_is',\n",
       "  'is_a',\n",
       "  'a_spokesman',\n",
       "  'spokesman_for',\n",
       "  'for_New',\n",
       "  'New_York',\n",
       "  \"York_City's\",\n",
       "  \"City's_Health\",\n",
       "  'Health_Department'],\n",
       " ['New',\n",
       "  'York',\n",
       "  'has',\n",
       "  'been',\n",
       "  'one',\n",
       "  'of',\n",
       "  'the',\n",
       "  'states',\n",
       "  'hit',\n",
       "  'hardest',\n",
       "  'by',\n",
       "  'Coronavirus',\n",
       "  'New_York',\n",
       "  'York_has',\n",
       "  'has_been',\n",
       "  'been_one',\n",
       "  'one_of',\n",
       "  'of_the',\n",
       "  'the_states',\n",
       "  'states_hit',\n",
       "  'hit_hardest',\n",
       "  'hardest_by',\n",
       "  'by_Coronavirus']]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents_uniandbigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bird\tcat\tchair\tdog\tloved\tsofa\tthe\n",
      "0.0\t0.52\t0.0\t0.0\t0.31\t0.52\t0.61\n",
      "0.0\t0.0\t0.42\t0.55\t0.32\t0.0\t0.65\n",
      "0.55\t0.0\t0.42\t0.0\t0.32\t0.0\t0.65\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "documents = ['the cat loved the sofa',\n",
    "             'the dog loved the chair',\n",
    "             'the bird loved the chair']\n",
    "\n",
    "vec = TfidfVectorizer()\n",
    "vec.fit_transform(documents)\n",
    "\n",
    "# just for printing nicely\n",
    "print(\"\\t\".join(vec.get_feature_names()))\n",
    "for row in vec.transform(documents).todense():\n",
    "    print(\"\\t\".join([f\"{float(e):.2}\" for e in row[0].tolist()[0]]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
